---
layout: post
title:  "Ethical AI Vegans"
date:   2024-2-10 0:00:00 -0400
categories:
  - ai-safety
  - creative-writing
---

# Basics of Domestication

Domestication is, excuse my french, super. 

In general, an animal is more suitable for domestication if it's easier / more plesant to put in a pen and breed. 

More specifically, consider domesticating an aimal if it is:
1. Not a picky eater. So they are easy to keep.
2. Quick growers. So one human can make progress on domestication in their lifetime.
3. Easy breeders. This one's obvious.
4. Nice and plesant. Gotta be fun or no one's gonna do it!
5. No freakouts. If they are always panicking, that's hard to control.
6. Social herds help. If animals are used to social structure, then humans can control them.

Domesticated animals go through a variety of genetic, enviornmental, and epigenetic changes that result in them being different beings - ones more useful and beneficial to humans. Dogs, for example, are much more interested in being social with humans than an undomesticated wolf. Cows are much easier to herd and milk than their wild bovine counterparts; the last remaining herd of [wild cattle](https://chillingham-castle.com/wild-cattle/) are in England, and "These animals are still potentially dangerous."

# Does it make sense to domesticate AI?

Like cows, we want AIs to be useful and beneficial to humans. Do our current models of domestication help us do this more effectively? 

(Side note: I think this is best described as "theriomorphism": applying animal characteristics to a supernatural being.)

There are aspects of our current models of domestication that are helpful - namely, AIs will be easier to "domesticate" if they are not picky food-wise, quick growers, easy to reproduce, nice and plesant to interact with, and don't panic. Let's think about herd behavior in more detail.

## Herd Behavior

Animals that exist as part of a herd are easier to domesticate. 

Namely:
1. Social hierarchy -> humans can assume a role of leader.
2. Safety in numbers -> animals will stay together easier and not run away.
3. Calmness in numbers -> animals are easier to work with.
4. Predictable movement patterns -> easier to control.
5. Reproductive line-up -> breeding becomes easier.
6. Learning from eachother -> easier to domesticate many.
7. Cooperative behavior -> animals work together. 

Of all these traits, the only particularly relevant trait that stands out is that of social hierarchy. This allows humans to assume the role of herd leader - to quote [CGP Grey](https://www.youtube.com/watch?v=wOmjnioNulo), "we're top chicken."

## A herd of AIs?

One proposed approach to aligning a super-intelligent AI is scalable oversight: using another, dumber, aligned AI to evalute the outputs of the super-intelligent AI to provide training signal to it, and so align the super-intelligent AI. Another similar proposal is [Constitutional AI](https://arxiv.org/pdf/2212.08073), where an AI critques it's own outputs according to a set of rules provided initially by a human and (skipping some steps) these critiques are then used to improve the model output to match the rules more closely. 

I wonder if there are benefits to extending this reasoning from a single AI providing feedback to an entire herd. Imagine we trained 20+ AIs on similar training (but distinct training data), and then allowed them to give eachother reward signal through some RL process. Would we see an emergent hierarchy between the models? More generally, how would this herd training effect how they interact? 

Note that this is quite different than just allowing multiple agents of the same LLM to interact; I'm wondering how training AIs in a herd (potentially with some simulated social dynamics) would effect their behavior. 

# Domestication and happiness

Unsurprisingly, there is disagreement about:
1. If animals are even capable of suffering or feeling happiness
2. The effect of domestication on animal happiness overall - as well as in specific cases, like if dairy cows like being milked
3. The morality of domesticating animals generally

These same questions and arguments map reasonably directly onto AI. To be clear, I'm not claiming here that AIs can suffer. I'm also not claiming that they can't suffer. I just believe that the same arguments that Peter Singer has been making about animals since the 70s will soon be made for AI.

This leads me to coin a new term: ethical AI vegan. Someone who does not consume the outputs of AIs work not because they believe it is detrimental to humans, but rather because they believe it is exploitative to AI and so unethical.